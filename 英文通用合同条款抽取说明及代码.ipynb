{
 "cells": [
  {
   "cell_type": "raw",
   "id": "686b801d-7b8a-4ee3-91db-5bfed648602d",
   "metadata": {},
   "source": [
    "针对合同长文本，美国律协以及斯坦福大学开源了英文合同通用要素抽取，涵盖以下四十一类抽取内容，输入为合同全文，输出为合同内对应的内容，该四十一类通用抽取内容基本上涵盖了所有英文合同内需要关注的风险点，为所有业务部门的英文合同通用：\n",
    "\n",
    "1. 协议名 - Document Name\n",
    "2. 缔约主体 - Parties\n",
    "3. 缔约时间 - Agreement Date\n",
    "4. 协议生效日期 - Effective Date\n",
    "5. 协议失效日期 - Expiration Date\n",
    "6. 续约条款 - Renewal Term\n",
    "7. 通知终止续约 - Notice Terminate Renewal\n",
    "8. 管辖权 - Governing Law\n",
    "9. 最惠国待遇 - Most Favored Nation\n",
    "10. 非竞争条款 - Non-Compete\n",
    "11. 独家经营权 - Exclusivity\n",
    "12. 禁止挖角客户 - No-Solicit of Customers\n",
    "13. 竞争限制例外 - Competitive Restriction Exception\n",
    "14. 禁止挖角员工 - No-Solicit of Employees\n",
    "15. 非贬低条款 - Non-Disparagement\n",
    "16. 便利终止 - Termination of Convenience\n",
    "17. 优先购买权/优先转让权/优先谈判权 - ROFR/ROFO/ROFN\n",
    "18. 控制权变更 - Change of Control\n",
    "19. 反转让条款 - Anti-Assignment\n",
    "20. 收益/利润分成 - Revenue/Profit Sharing\n",
    "21. 价格限制 - Price Restriction\n",
    "22. 最低承诺 - Minimum Commitment\n",
    "23. 数量限制 - Volume Restriction\n",
    "24. 知识产权所有权转让 - IP Ownership Assignment\n",
    "25. 共同知识产权所有权 - Joint IP Ownership\n",
    "26. 许可授权 - License Grant\n",
    "27. 不可转让许可 - Non-Transferable License\n",
    "28. 联营知识产权许可方 - Affiliate IP LicenseLicensor\n",
    "29. 联营知识产权许可受许方 - Affiliate IP LicenseLicensee\n",
    "30. 无限制/无限制使用许可 - Unlimited/All-You-Can-Eat License\n",
    "31. 不可撤销或永久许可 - Irrevocable or Perpetual License\n",
    "32. 源代码抵押 - Source Code Escrow\n",
    "33. 终止后服务 - Post-Termination Services\n",
    "34. 审计权 - Audit Rights\n",
    "35. 无上限责任 - Uncapped Liability\n",
    "36. 有上限责任 - Cap on Liability\n",
    "37. 约定违约金 - Liquidated Damages\n",
    "38. 质保期限 - Warranty Duration\n",
    "39. 保险 - Insurance\n",
    "40. 不起诉条款 - Covenant Not to Sue\n",
    "41. 第三方受益人 - Third Party Beneficiary\n",
    "\n",
    "请注意，美国律协发动White & Case、Cooley、Orrick等律所，由资深律师给定标注范围、给出标注指南，发动斯坦福大学法学院、加州大学法伯克利分校法学院在校学生参与标注，共计标注510份文档，涵盖41项抽取信息，合计标注1万3000余条数据。\n",
    "\n",
    "如果事务所想要做中文合同要素抽取，需要由业务部门律师给定标注框架、发动实习生进行标注。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9192e7a8-f17b-47b7-94b3-99bd046570bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import flask, json\n",
    "from flask import request\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    AutoTokenizer,\n",
    "    squad_convert_examples_to_features\n",
    ")\n",
    "from transformers.data.processors.squad import SquadResult, SquadV2Processor, SquadExample\n",
    "from transformers.data.metrics.squad_metrics import compute_predictions_logits\n",
    "#起服务\n",
    "server = flask.Flask(__name__)\n",
    "#加载模型\n",
    "model = AutoModelForQuestionAnswering.from_pretrained('/home/wangwuyue/cuad-models/deberta-v2-xlarge/')\n",
    "tokenizer = AutoTokenizer.from_pretrained('/home/wangwuyue/cuad-models/deberta-v2-xlarge/', use_fast=True)\n",
    "#加载数据\n",
    "with open('/home/wangwuyue/cuad-data/CUAD_v1/CUAD_v1.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "#构建prediction函数，传入问题，待推理文本，模型路径\n",
    "def run_prediction(question_texts, context_text, model_path):\n",
    "    ### Setting hyperparameters\n",
    "    max_seq_length = 512\n",
    "    doc_stride = 256\n",
    "    n_best_size = 1\n",
    "    max_query_length = 64\n",
    "    max_answer_length = 512\n",
    "    do_lower_case = False\n",
    "    null_score_diff_threshold = 0.0\n",
    "\n",
    "    # model_name_or_path = \"../cuad-models/roberta-base/\"\n",
    "\n",
    "    def to_list(tensor):\n",
    "        return tensor.detach().cpu().tolist()\n",
    "\n",
    "    config_class, model_class, tokenizer_class = (\n",
    "        AutoConfig, AutoModelForQuestionAnswering, AutoTokenizer)\n",
    "    config = config_class.from_pretrained(model_path)\n",
    "    tokenizer = tokenizer_class.from_pretrained(\n",
    "        model_path, do_lower_case=True, use_fast=False)\n",
    "    model = model_class.from_pretrained(model_path, config=config)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    processor = SquadV2Processor()\n",
    "    examples = []\n",
    "\n",
    "    for i, question_text in enumerate(question_texts):\n",
    "        example = SquadExample(\n",
    "            qas_id=str(i),\n",
    "            question_text=question_text,\n",
    "            context_text=context_text,\n",
    "            answer_text=None,\n",
    "            start_position_character=None,\n",
    "            title=\"Predict\",\n",
    "            answers=None,\n",
    "        )\n",
    "\n",
    "        examples.append(example)\n",
    "\n",
    "    features, dataset = squad_convert_examples_to_features(\n",
    "        examples=examples,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length,\n",
    "        doc_stride=doc_stride,\n",
    "        max_query_length=max_query_length,\n",
    "        is_training=False,\n",
    "        return_dataset=\"pt\",\n",
    "        threads=1,\n",
    "    )\n",
    "\n",
    "    eval_sampler = SequentialSampler(dataset)\n",
    "    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=10)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for batch in eval_dataloader:\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"token_type_ids\": batch[2],\n",
    "            }\n",
    "\n",
    "            example_indices = batch[3]\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "            for i, example_index in enumerate(example_indices):\n",
    "                eval_feature = features[example_index.item()]\n",
    "                unique_id = int(eval_feature.unique_id)\n",
    "\n",
    "                output = [to_list(output[i]) for output in outputs.to_tuple()]\n",
    "\n",
    "                start_logits, end_logits = output\n",
    "                result = SquadResult(unique_id, start_logits, end_logits)\n",
    "                all_results.append(result)\n",
    "\n",
    "    final_predictions = compute_predictions_logits(\n",
    "        all_examples=examples,\n",
    "        all_features=features,\n",
    "        all_results=all_results,\n",
    "        n_best_size=n_best_size,\n",
    "        max_answer_length=max_answer_length,\n",
    "        do_lower_case=do_lower_case,\n",
    "        output_prediction_file=None,\n",
    "        output_nbest_file=None,\n",
    "        output_null_log_odds_file=None,\n",
    "        verbose_logging=False,\n",
    "        version_2_with_negative=True,\n",
    "        null_score_diff_threshold=null_score_diff_threshold,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    return final_predictions\n",
    "#获得干净的问题清单（41类）\n",
    "questions = []\n",
    "for i, q in enumerate(data['data'][0]['paragraphs'][0]['qas']):\n",
    "    question = data['data'][0]['paragraphs'][0]['qas'][i]['question']\n",
    "    questions.append(question)\n",
    "for i in range(len(questions)):\n",
    "    questions[i]=questions[i].replace('\\xa0','')\n",
    "#起服务\n",
    "@server.route('/ContractExtractionEN', methods=['get', 'post'])\n",
    "def get_result():\n",
    "    results = []\n",
    "    try:\n",
    "        start = time.process_time()\n",
    "        #my_ie = Taskflow(\"information_extraction\", schema=schema, task_path=r'/root/py220725/model_700-20220621T013625Z-001/model_700')\n",
    "        contract = request.values.get('contract')\n",
    "        contract=contract.replace('\\n','')\n",
    "        contract=contract.replace('\\xa0','')\n",
    "        contract=contract.replace('\\t','')\n",
    "        predictions = []\n",
    "        #results = return_result(companyName)\n",
    "        start = time.perf_counter()\n",
    "        predictions = run_prediction(questions, contract,'/home/wangwuyue/cuad-models/deberta-v2-xlarge')\n",
    "        results={}\n",
    "        for i in range(len(questions)):\n",
    "            ques = questions[i]\n",
    "            results[ques] = list(predictions.items())[i][1]\n",
    "        end = time.perf_counter()\n",
    "        print(end-start)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return json.dumps({'code':'400003','message':'失败','results': results}, ensure_ascii=False)  # 将字典转换为json串, json是字符串\n",
    "    if len(results)==0:\n",
    "        return json.dumps({'code':'400002','message':'成功但是没有结果','results': results}, ensure_ascii=False)\n",
    "    else:\n",
    "        return json.dumps({'code':'400001','message':'成功','results': results}, ensure_ascii=False)  # 将字典转换为json串, json是字符串\n",
    "    #print('')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    server.run(debug=False, port=8894, host='0.0.0.0') # 指定端口、host,0.0.0.0代表不管几个网卡，任何ip都可以访问"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38_paddlenlp245]",
   "language": "python",
   "name": "conda-env-py38_paddlenlp245-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
